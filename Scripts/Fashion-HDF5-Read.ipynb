{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform as st\n",
    "import numpy as np\n",
    "import h5py\n",
    "import io\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retreiveImages(hf, file_path):\n",
    "\n",
    "    img_names = hf['Anno_fine'][file_path]\n",
    "    img_names = np.array(img_names)\n",
    "    strip = np.vectorize(lambda x : x.strip())\n",
    "    img_names = strip(img_names)\n",
    "    \n",
    "    imgs = []\n",
    "    for img_name in tqdm(img_names):\n",
    "        img = np.asarray(Image.open(io.BytesIO(np.array(hf[img_name]))))\n",
    "\n",
    "\n",
    "        imgs.append(img)\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequence(hf, file_name):\n",
    "    ret = hf['Anno_fine'][file_name]\n",
    "    ret = np.array(ret)\n",
    "    ret = [[int(y) for y in x.strip().split()] for x in ret]\n",
    "    return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(index, imgs, bboxs, landmarks):\n",
    "    img = imgs[index]\n",
    "\n",
    "    target_size = 301\n",
    "\n",
    "    y_diff = target_size - img.shape[0]\n",
    "    x_diff = target_size - img.shape[1]\n",
    "\n",
    "    x_diff_left = math.floor(x_diff/2)\n",
    "    x_diff_right = math.ceil(x_diff/2)\n",
    "\n",
    "    y_diff_up = math.floor(y_diff/2)\n",
    "    y_diff_down = math.ceil(y_diff/2)\n",
    "\n",
    "    left_padding = np.max(img) * np.ones((img.shape[0], x_diff_left, 3), dtype=np.uint8)\n",
    "    right_padding = np.max(img) * np.ones((img.shape[0], x_diff_right, 3), dtype=np.uint8)\n",
    "\n",
    "    new_img = np.hstack((left_padding, img, right_padding))\n",
    "\n",
    "    up_padding = np.max(img) * np.ones((y_diff_up, target_size, 3), dtype=np.uint8)\n",
    "    down_padding = np.max(img) * np.ones((y_diff_down, target_size, 3), dtype=np.uint8)\n",
    "\n",
    "    new_img = np.vstack((up_padding, new_img, down_padding))\n",
    "    \n",
    "    i = Image.fromarray(new_img)\n",
    "    i = i.resize(size=(224, 224))\n",
    "\n",
    "    imgs[index] = np.array(i)\n",
    "    bboxs[index] = [sum(x) for x in zip(train_bboxs[index], [x_diff_left, y_diff_up] * 2)]\n",
    "    landmarks[index] = [sum(x) for x in zip(train_landmarks[index], [x_diff_left, y_diff_up] * 8)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=14000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea27114588e6414b8d9d0f100471baf7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=14000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c5e76e86cf046cf85d8f275f68d0b4f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File('../data/data.h5', 'r')\n",
    "\n",
    "train_imgs = retreiveImages(hf, 'train.txt')\n",
    "train_attrs = getSequence(hf, 'train_attr.txt')\n",
    "train_categories = getSequence(hf, 'train_cate.txt')\n",
    "train_bboxs = getSequence(hf, 'train_bbox.txt')\n",
    "train_landmarks = getSequence(hf, 'train_landmarks.txt')\n",
    "\n",
    "for i in tqdm(range(len(train_imgs))):\n",
    "    preprocess(i, train_imgs, train_bboxs, train_landmarks)\n",
    "\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('../data/train_fine.h5', 'w')\n",
    "hf.create_dataset('img', data=np.array(train_imgs))\n",
    "hf.create_dataset('attr', data=train_attrs)\n",
    "hf.create_dataset('category', data=train_categories)\n",
    "hf.create_dataset('bbox', data=train_bboxs)\n",
    "hf.create_dataset('landmark', data=train_landmarks)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5fb0041e33994a6d8c8b5e2d83d9c9b5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a8d8f4e4620489abbe8975e2d6181c4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File('../data/data.h5', 'r')\n",
    "\n",
    "train_imgs = retreiveImages(hf, 'test.txt')\n",
    "train_attrs = getSequence(hf, 'test_attr.txt')\n",
    "train_categories = getSequence(hf, 'test_cate.txt')\n",
    "train_bboxs = getSequence(hf, 'test_bbox.txt')\n",
    "train_landmarks = getSequence(hf, 'test_landmarks.txt')\n",
    "\n",
    "for i in tqdm(range(len(train_imgs))):\n",
    "    preprocess(i, train_imgs, train_bboxs, train_landmarks)\n",
    "\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('../data/test_fine.h5', 'w')\n",
    "hf.create_dataset('img', data=np.array(train_imgs))\n",
    "hf.create_dataset('attr', data=train_attrs)\n",
    "hf.create_dataset('category', data=train_categories)\n",
    "hf.create_dataset('bbox', data=train_bboxs)\n",
    "hf.create_dataset('landmark', data=train_landmarks)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}